<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:dc='http://purl.org/dc/elements/1.1/'>
    <channel>
        <title>Azure - Tag - sheldonhull.com</title>
        <link>https://www.sheldonhull.com/tags/azure/</link>
        <description>Azure - Tag - sheldonhull.com</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Fri, 24 Jul 2020 19:00:00 -0500</lastBuildDate><atom:link href="https://www.sheldonhull.com/tags/azure/" rel="self" type="application/rss+xml" />

<item>
    <title>
        Getting Started with Stream Analytics
    </title>
    <link>
        https://www.sheldonhull.com/getting-started-with-stream-analytics/
    </link>
    <pubDate>
        Fri, 24 Jul 2020 19:00:00 -0500
    </pubDate>
    
    
    <guid>
        https://www.sheldonhull.com/getting-started-with-stream-analytics/
    </guid>
    <description>
        <![CDATA[
        
        
        
            
        
        <h2 id="resources" class="headerLink">
    <a href="#resources" class="header-mark"></a>Resources</h2><table>
<thead>
<tr>
<th>Resources</th>
</tr>
</thead>
<tbody>
<tr>
<td>If you want a schema reference for the json Application Insights produces // <a href="http://bit.ly/2S3kFlD" target="_blank" rel="noopener noreferrer">Azure Application Insights Data Model // Microsoft Docs</a></td>
</tr>
<tr>
<td>If you want to visualize last 90 days of App Insight Data with Grafana // <a href="http://bit.ly/2S1Kkv9" target="_blank" rel="noopener noreferrer">Monitor Azure services and applications using Grafana // Microsoft Docs</a></td>
</tr>
</tbody>
</table>
<h2 id="the-scenario" class="headerLink">
    <a href="#the-scenario" class="header-mark"></a>The Scenario</h2><p>Application insights is integrated into your application and is sending the results to Azure. In my case, it was blob storage. This can compromise your entire insights history.</p>
<p>Application Insights has some nice options to visualize data, Grafana included among them.
However, the data retention as of this time is still set to 90 days. This means historical reporting is limited, and you&rsquo;ll need to utilize <code>Continuous Export</code> in the Application Insights settings to stream out the content into blob storage to</p>
<h2 id="the-process" class="headerLink">
    <a href="#the-process" class="header-mark"></a>The process</h2><ol>
<li>Install Visual Studio Azure Plugin</li>
<li>Initialize a new Stream Analytics project in Visual Studio</li>
<li>Import some test data</li>
<li>(Optional) If using SQL Server as storage for stream analytics then design the schema.</li>
<li>Write your stream analytics sql, aka asql.</li>
<li>Debug and confirm you are happy with this.</li>
<li>Submit job to Azure (stream from now, or stream and backfill)</li>
<li>Configure Grafana or PowerBI to connect to your data and make management happy with pretty graphs.</li>
</ol>
<h2 id="install-visual-studio-azure-plugin" class="headerLink">
    <a href="#install-visual-studio-azure-plugin" class="header-mark"></a>Install Visual Studio Azure Plugin</h2><p>I don&rsquo;t think this would have been a feasible learning process without having run this through Visual Studio, as the web portal doesn&rsquo;t provide such a smooth experience.
Highly recommend using Visual Studio for this part.</p>
<p>Learning the ropes through the web interface can be helpful, but if you are exploring the data parsing you need a way to debug and test the results without waiting minutes to simply have a job start.
In addition, you need a way to see the parsed results from test data to ensure you are happy with the results.</p>
<h2 id="new-stream-analytics-project" class="headerLink">
    <a href="#new-stream-analytics-project" class="header-mark"></a>New Stream Analytics Project</h2><p><figure><a class="lightgallery" href="/images/2019-02-08_18-04-50-stream-analytics-project.png" title="stream analytics project" data-thumbnail="/images/2019-02-08_18-04-50-stream-analytics-project.png" data-sub-html="<h2>Stream Analytics In Visual Studio 2017</h2><p>stream analytics project</p>">
        
    </a><figcaption class="image-caption">Stream Analytics In Visual Studio 2017</figcaption>
    </figure></p>
<h2 id="setup-test-data" class="headerLink">
    <a href="#setup-test-data" class="header-mark"></a>Setup test data</h2><p>Grab some blob exports from your Azure storage and sample a few of the earliest and the latest of your json, placing into a single json file. Put this in your solution folder called inputs through Windows Explorer. After you&rsquo;ve done this, right click on the input file contained in your project and select <code>Add Local Input</code>. This local input is what you&rsquo;ll use to debug and test without having to wait for the cloud job. You&rsquo;ll be able to preview the content in Visual Studio just like when you run SQL Queries and review the results in the grid.</p>
<h2 id="design-sql-schema" class="headerLink">
    <a href="#design-sql-schema" class="header-mark"></a>Design SQL Schema</h2><p>Unique constraints create an index.
If you use a unique constraint, you need to be aware of the following info to avoid errors.</p>
<blockquote>
<p>When you configure Azure SQL database as output to a Stream Analytics job, it bulk inserts records into the destination table. In general, Azure stream analytics guarantees at least once delivery to the output sink, one can still achieve exactly-once delivery to SQL output when SQL table has a unique constraint defined.
Once unique key constraints are set up on the SQL table, and there are duplicate records being inserted into SQL table, Azure Stream Analytics removes the duplicate record.
<a href="http://bit.ly/2Bugzh0" target="_blank" rel="noopener noreferrer">Common issues in Stream Analytics and steps to troubleshoot
</a>
Using the warning above, create any unique constraints with the following syntax to avoid issues.</p>
</blockquote>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sql" data-lang="sql"><span class="line"><span class="cl"><span class="k">create</span><span class="w"> </span><span class="k">table</span><span class="w"> </span><span class="n">dbo</span><span class="p">.</span><span class="n">Example</span><span class="w"> </span><span class="p">(</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">...</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">,</span><span class="k">constraint</span><span class="w"> </span><span class="n">uq_TableName_internal_id_dimension_name</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="k">unique</span><span class="w"> </span><span class="p">(</span><span class="w"> </span><span class="n">internal_id</span><span class="p">,</span><span class="w"> </span><span class="n">dimension_name</span><span class="w"> </span><span class="p">)</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="p">(</span><span class="n">IGNORE_DUP_KEY</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="k">on</span><span class="p">)</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><h2 id="stream-analytics-query" class="headerLink">
    <a href="#stream-analytics-query" class="header-mark"></a>Stream Analytics Query</h2><blockquote>
<p>warning &ldquo;Design Considerations&rdquo;
Pay attention to the limits and also to the fact you aren&rsquo;t writing pure T-SQL in the <code>asaql</code> file. It&rsquo;s a much more limited analytics syntax that requires you to simplify some things you might do in TSQL. It does not support all TSQL features. <a href="https://docs.microsoft.com/en-us/stream-analytics-query/stream-analytics-query-language-reference" target="_blank" rel="noopener noreferrer">Stream Analytics Query Language Reference</a></p>
</blockquote>
<p>Take a look at the <a href="https://docs.microsoft.com/en-us/azure/azure-monitor/app/code-sample-export-sql-stream-analytics" target="_blank" rel="noopener noreferrer">query examples</a> on how to use <code>cross apply</code> and <code>into</code> to quickly create Sql Server tables.</p>
<h2 id="backfilling-historical-data" class="headerLink">
    <a href="#backfilling-historical-data" class="header-mark"></a>Backfilling Historical Data</h2><p>When you start the job, the default start job date can be changed.
Use custom date and then provide it the oldest data of your data.
For me this correctly initialized the historical import, resulting in a long running job that populated all the historical data from 2017 and on.</p>
<h2 id="configure-grafana-or-powerbi" class="headerLink">
    <a href="#configure-grafana-or-powerbi" class="header-mark"></a>Configure Grafana or PowerBI</h2><p>Initially I started with Power BI.
However, I found out that Grafana 5.1 &gt; has data source plugins for Azure and Application insights, along with dashboard to get you started.
I&rsquo;ve written on Grafana and InfluxDB in the past and am huge fan of Grafana.
I&rsquo;d highly suggest you explore that, as it&rsquo;s free, while publishing to a workspace with PowerBI can require a subscription, that might not be included in your current MSDN or Office 365 membership. YMMV.</p>
<h3 id="filter-syntax" class="headerLink">
    <a href="#filter-syntax" class="header-mark"></a>Filter Syntax</h3><p><a href="http://bit.ly/2Uft9bv" target="_blank" rel="noopener noreferrer">Filter Syntax Reference</a></p>
<p>I had to search to find details on the filtering but ended up finding the right syntax for doing partial match searches in the Filter Syntax Reference linked above.
This also provides direct links to their ApiExplorer which allows testing and constructing api queries to confirm your syntax.</p>
<p>If you had a custom metric you were grouping by that was <code>customEvent\name</code> then the filter to match something like a save action could be:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-text" data-lang="text"><span class="line"><span class="cl">startswith(customEvent/name, &#39;Save&#39;)
</span></span></code></pre></td></tr></table>
</div>
</div><p>This would match the custom metrics you had saved that might provide more granularity that you&rsquo;d normally have to specify like:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-text" data-lang="text"><span class="line"><span class="cl">customEvent/Name eq &#39;Save(Customer)&#39;
</span></span><span class="line"><span class="cl">customEvent/Name eq &#39;Save(Me)&#39;
</span></span><span class="line"><span class="cl">customEvent/Name eq &#39;Save(Time)&#39;
</span></span><span class="line"><span class="cl">customEvent/Name eq &#39;Save(Tacos)&#39;
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="wrap-up" class="headerLink">
    <a href="#wrap-up" class="header-mark"></a>Wrap-up</h2><p>I only did this one project so unfortunately I don&rsquo;t have exhaustive notes this.
However, some of the filter syntax and links were helpful to get me jump started on this and hopefully they&rsquo;ll be useful to anyone trying to get up and running like I had too.</p>

        ]]>
    </description>
</item>


<item>
    <title>
        Painless Synchronization of Azure Blob Storage with AWS S3
    </title>
    <link>
        https://www.sheldonhull.com/painless-synchronization-of-azure-blob-storage-with-aws-s3/
    </link>
    <pubDate>
        Tue, 16 Jul 2019 13:00:00 &#43;0000
    </pubDate>
    
    
    <guid>
        https://www.sheldonhull.com/painless-synchronization-of-azure-blob-storage-with-aws-s3/
    </guid>
    <description>
        <![CDATA[
        
        
        
            
        
        <h2 id="synchronization" class="headerLink">
    <a href="#synchronization" class="header-mark"></a>Synchronization</h2><p>Moving data between two cloud providers can be painful, and require more provider scripting if doing api calls. For this, you can benefit from a tool that abstracts the calls into a seamless synchronization tool.</p>
<p>I&rsquo;ve used RClone before when needing to deduplicate several terabytes of data in my own Google Drive, so I figured I&rsquo;d see if it could help me sync up 25GB of json files from Azure to S3.</p>
<p>Very happy to report it worked perfectly, and with only a couple minutes of refamilarizing myself with the tool setup.</p>
<h2 id="install-rclone" class="headerLink">
    <a href="#install-rclone" class="header-mark"></a>Install RClone</h2><p>For windows users, it&rsquo;s as easy as leveraging Chocolatey and running</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-powershell" data-lang="powershell"><span class="line"><span class="cl"><span class="n">choco</span> <span class="n">upgrade</span> <span class="n">rclone</span> <span class="n">-y</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="setup-providers" class="headerLink">
    <a href="#setup-providers" class="header-mark"></a>Setup Providers</h2><p>Go through <code>rclone config</code> dialogue and setup your cloud provider. In my case, I setup Azure as a provider to connect to blob storage, and then AWS with s3.</p>
<div
    class="details admonition info
      open
    "
  >
    <div class="details-summary admonition-title">
      <i
        class="icon fas fa-info-circle fa-fw"
      ></i>
      Cloud to Cloud
      <i class="details-icon fas fa-angle-right fa-fw"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">Providers that support cloud to cloud based calls without copying locally are provided in the section for <a href="http://bit.ly/2LEOSrR" target="_blank" rel="noopener noreferrer">Optional Features</a> where you can view the operations that support calls</div>
    </div>
  </div>
<h2 id="initialize-sync" class="headerLink">
    <a href="#initialize-sync" class="header-mark"></a>Initialize Sync</h2><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-powershell" data-lang="powershell"><span class="line"><span class="cl"><span class="n">rclone</span> <span class="nb">copy </span><span class="n">azure</span><span class="err">:</span><span class="n">containername</span> <span class="n">s3</span><span class="err">:</span><span class="n">bucketname</span><span class="p">/</span><span class="n">keyprefix</span> <span class="p">-</span><span class="n">-log-level</span> <span class="n">ERROR</span> <span class="p">-</span><span class="n">-progress</span> <span class="p">-</span><span class="n">-dry-run</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="wrap-up" class="headerLink">
    <a href="#wrap-up" class="header-mark"></a>Wrap-up</h2><p>Take a look at this if you need a simple way to grab some data from one provider and leverage in another and you might want to save yourself some time on learning provider specific api calls. I&rsquo;ve found tools like this, Terraform, and others that help abstract the api calls can be a great resource as you can leverage one syntax to work with two completely different providers and eliminate a lot of effort in coding.</p>

        ]]>
    </description>
</item>


<item>
    <title>
        Azure
    </title>
    <link>
        https://www.sheldonhull.com/notes/development/azure/
    </link>
    <pubDate>
        Mon, 01 Jan 0001 00:00:00 &#43;0000
    </pubDate>
    
    
    <guid>
        https://www.sheldonhull.com/notes/development/azure/
    </guid>
    <description>
        <![CDATA[
        
        
        
            
        
        
        ]]>
    </description>
</item>


<item>
    <title>
        Azure CLI
    </title>
    <link>
        https://www.sheldonhull.com/notes/development/azure/azure-cli/
    </link>
    <pubDate>
        Mon, 01 Jan 0001 00:00:00 &#43;0000
    </pubDate>
    
    
    <guid>
        https://www.sheldonhull.com/notes/development/azure/azure-cli/
    </guid>
    <description>
        <![CDATA[
        
        
        
            
        
        <div
    class="details admonition info
      open
    "
  >
    <div class="details-summary admonition-title">
      <i
        class="icon fas fa-info-circle fa-fw"
      ></i>
      Requirements
      <i class="details-icon fas fa-angle-right fa-fw"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content"><ul>
<li>Azure CLI</li>
<li><a href="https://github.com/charmbracelet/gum" target="_blank" rel="noopener noreferrer">gum</a></li>
</ul>
</div>
    </div>
  </div>
<h2 id="azure-cli" class="headerLink">
    <a href="#azure-cli" class="header-mark"></a>Azure CLI</h2><p>I prefer the PowerShell module, but the azure CLI is pretty solid for those times when something with .NET just won&rsquo;t cooperate&hellip;</p>
<h2 id="storage-for-state-files" class="headerLink">
    <a href="#storage-for-state-files" class="header-mark"></a>Storage for State Files</h2><p>I found the need to create storage buckets pretty important if running pulumi or terraform.
Makes sense to do this via the CLI for basic usage as it&rsquo;s a chicken or the egg problem.</p>
<p>Start with <code>az login</code>.</p>
<h3 id="inputs" class="headerLink">
    <a href="#inputs" class="header-mark"></a>Inputs</h3><p>This assumes you&rsquo;ll place the storage account in an existing resource group.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"><span class="nv">AZURE_SUBSCRIPTION_ID</span><span class="o">=</span><span class="s2">&#34;</span><span class="k">$(</span>gum input --header <span class="s1">&#39;Subscription ID&#39;</span><span class="k">)</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl">az account <span class="nb">set</span> --subscription<span class="o">=</span><span class="s2">&#34;</span><span class="si">${</span><span class="nv">AZURE_SUBSCRIPTION_ID</span><span class="si">}</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl"><span class="nv">RESOURCE_GROUP_NAME</span><span class="o">=</span><span class="s2">&#34;</span><span class="k">$(</span>gum input --header <span class="s1">&#39;Resource Group name&#39;</span><span class="k">)</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl"><span class="nv">STORAGE_ACCOUNT_NAME</span><span class="o">=</span><span class="s2">&#34;</span><span class="k">$(</span>gum input --header <span class="s1">&#39;Storage Account Name (will have random suffix added)&#39;</span><span class="k">)</span><span class="si">${</span><span class="nv">RANDOM</span><span class="si">}</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl"><span class="nv">CONTAINER_NAME</span><span class="o">=</span><span class="s2">&#34;</span><span class="k">$(</span>gum input --header <span class="s1">&#39;Container name in the storage account&#39;</span><span class="k">)</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl"><span class="nv">CONTINUE</span><span class="o">=</span><span class="m">1</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="create-the-storage-account" class="headerLink">
    <a href="#create-the-storage-account" class="header-mark"></a>Create the storage account</h3><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">az storage account create <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    --resource-group <span class="s2">&#34;</span><span class="nv">$RESOURCE_GROUP_NAME</span><span class="s2">&#34;</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    --name <span class="s2">&#34;</span><span class="nv">$STORAGE_ACCOUNT_NAME</span><span class="s2">&#34;</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    --sku Standard_LRS <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    --encryption-services blob <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    --min-tls-version <span class="s2">&#34;TLS1_2&#34;</span><span class="err">&#39;</span>
</span></span><span class="line"><span class="cl">az storage container create --name <span class="s2">&#34;</span><span class="si">${</span><span class="nv">CONTAINER_NAME</span><span class="si">}</span><span class="s2">&#34;</span> --account-name <span class="s2">&#34;</span><span class="si">${</span><span class="nv">STORAGE_ACCOUNT_NAME</span><span class="si">}</span><span class="s2">&#34;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="assign-permissions" class="headerLink">
    <a href="#assign-permissions" class="header-mark"></a>Assign permissions</h3><p>This is assuming the email is the principal lookup value.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"><span class="nv">PRINCIPAL_EMAIL</span><span class="o">=</span><span class="s2">&#34;</span><span class="k">$(</span>gum input --header <span class="s1">&#39;Enter the principal email you want to give access&#39;</span><span class="k">)</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl"><span class="nv">PRINCIPAL_ID</span><span class="o">=</span><span class="s2">&#34;</span><span class="k">$(</span>az ad user list --query <span class="s2">&#34;[?mail==&#39;</span><span class="si">${</span><span class="nv">PRINCIPAL_EMAIL</span><span class="si">}</span><span class="s2">&#39;].id&#34;</span> -o tsv<span class="k">)</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="o">[[</span> -z <span class="s2">&#34;</span><span class="si">${</span><span class="nv">PRINCIPAL_ID</span><span class="si">}</span><span class="s2">&#34;</span> <span class="o">]]</span><span class="p">;</span> <span class="k">then</span>
</span></span><span class="line"><span class="cl">    <span class="nb">echo</span> <span class="s2">&#34;No user found with email: &#39;</span><span class="si">${</span><span class="nv">PRINCIPAL_EMAIL</span><span class="si">}</span><span class="s2">&#39;&#34;</span>
</span></span><span class="line"><span class="cl">    gum confirm <span class="s1">&#39;continue?&#39;</span> <span class="o">||</span> <span class="nv">CONTINUE</span><span class="o">=</span><span class="m">0</span>
</span></span><span class="line"><span class="cl"><span class="k">else</span>
</span></span><span class="line"><span class="cl">    <span class="nv">CONTINUE</span><span class="o">=</span><span class="m">1</span>
</span></span><span class="line"><span class="cl">    <span class="nb">echo</span> <span class="s2">&#34;üëç found user with email: &#39;</span><span class="si">${</span><span class="nv">PRINCIPAL_EMAIL</span><span class="si">}</span><span class="s2">&#39; and id: </span><span class="si">${</span><span class="nv">PRINCIPAL_ID</span><span class="si">}</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl"><span class="k">fi</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="o">[[</span> <span class="s2">&#34;</span><span class="nv">$CONTINUE</span><span class="s2">&#34;</span> -ne <span class="m">1</span> <span class="o">]]</span><span class="p">;</span> <span class="k">then</span>
</span></span><span class="line"><span class="cl">    <span class="nb">echo</span> <span class="s2">&#34;‚ùå can&#39;t continue&#34;</span>
</span></span><span class="line"><span class="cl"><span class="k">else</span>
</span></span><span class="line"><span class="cl">    <span class="nv">STORAGE_ACCOUNT_ID</span><span class="o">=</span><span class="k">$(</span>az storage account show --name <span class="s2">&#34;</span><span class="si">${</span><span class="nv">STORAGE_ACCOUNT_NAME</span><span class="si">}</span><span class="s2">&#34;</span> --resource-group <span class="s2">&#34;</span><span class="si">${</span><span class="nv">RESOURCE_GROUP_NAME</span><span class="si">}</span><span class="s2">&#34;</span> --query id --output tsv<span class="k">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">echo</span> <span class="s2">&#34;The storage account id is </span><span class="si">${</span><span class="nv">STORAGE_ACCOUNT_ID</span><span class="si">}</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl">    az role assignment create --assignee <span class="s2">&#34;</span><span class="si">${</span><span class="nv">PRINCIPAL_ID</span><span class="si">}</span><span class="s2">&#34;</span> --role <span class="s2">&#34;Storage Blob Data Contributor&#34;</span> --scope <span class="s2">&#34;</span><span class="si">${</span><span class="nv">STORAGE_ACCOUNT_ID</span><span class="si">}</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl"><span class="k">fi</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="copy-terraform-state-file-up" class="headerLink">
    <a href="#copy-terraform-state-file-up" class="header-mark"></a>Copy Terraform State File Up</h3><p>If you need to migrate terraform storage from Terraform Cloud to azure storage, then you can jump start by grabbing the keys here:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"><span class="nv">AZURE_ACCOUNT_ID</span><span class="o">=</span><span class="s2">&#34;</span><span class="k">$(</span>az account show --subscription <span class="s2">&#34;</span><span class="si">${</span><span class="nv">AZURE_SUBSCRIPTION_ID</span><span class="si">}</span><span class="s2">&#34;</span> --query <span class="s1">&#39;id&#39;</span> --output tsv<span class="k">)</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl">gum format <span class="s2">&#34;AZURE_ACCOUNT_ID=&#39;</span><span class="si">${</span><span class="nv">AZURE_ACCOUNT_ID</span><span class="si">}</span><span class="s2">&#39;&#34;</span>
</span></span><span class="line"><span class="cl">gum format <span class="s1">&#39;## azure storage keys, use to migrate backend if required&#39;</span>
</span></span><span class="line"><span class="cl">gum format <span class="s1">&#39;&gt; export ARM_ACCESS_KEY=&#39;</span>
</span></span><span class="line"><span class="cl">az storage account keys list --resource-group <span class="s2">&#34;</span><span class="si">${</span><span class="nv">RESOURCE_GROUP_NAME</span><span class="si">}</span><span class="s2">&#34;</span> --account-name <span class="s2">&#34;</span><span class="si">${</span><span class="nv">STORAGE_ACCOUNT_NAME</span><span class="si">}</span><span class="s2">&#34;</span> <span class="p">|</span> gum format --type code --language <span class="s1">&#39;json&#39;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">gum format <span class="s1">&#39;### If you need to migrate your state from Terraform Cloud, try this approach&#39;</span>
</span></span><span class="line"><span class="cl">gum format --language <span class="s1">&#39;shell&#39;</span> --type code <span class="s">&lt;&lt;EOF
</span></span></span><span class="line"><span class="cl"><span class="s">mkdir -p terraform.tfstate.d
</span></span></span><span class="line"><span class="cl"><span class="s">terraform state pull &gt; terraform.tfstate.d/terraform.tfstate
</span></span></span><span class="line"><span class="cl"><span class="s">mv .terraform/terraform.tfstate .terraform/terraform.tfstate.old
</span></span></span><span class="line"><span class="cl"><span class="s">az storage blob upload \\
</span></span></span><span class="line"><span class="cl"><span class="s">    --account-name &#34;${STORAGE_ACCOUNT_NAME}&#34; \\
</span></span></span><span class="line"><span class="cl"><span class="s">    --container-name &#34;${CONTAINER_NAME}&#34; \\
</span></span></span><span class="line"><span class="cl"><span class="s">    --name terraform.tfstate --type block \\
</span></span></span><span class="line"><span class="cl"><span class="s">    --file terraform.tfstate.d/terraform.tfstate
</span></span></span><span class="line"><span class="cl"><span class="s">terraform init
</span></span></span><span class="line"><span class="cl"><span class="s">EOF</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="add-terraform-version--provider-files" class="headerLink">
    <a href="#add-terraform-version--provider-files" class="header-mark"></a>Add Terraform Version &amp; Provider Files</h3><p>Finally, update your terraform files with some pre-built snippets nicely formatted in your terminal.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">gum format <span class="s1">&#39;`## backend.tf`&#39;</span>
</span></span><span class="line"><span class="cl">gum format --type code --language<span class="o">=</span><span class="s2">&#34;HCL2&#34;</span> <span class="s">&lt;&lt;EOF
</span></span></span><span class="line"><span class="cl"><span class="s">terraform {
</span></span></span><span class="line"><span class="cl"><span class="s">  backend &#34;azurerm&#34; {
</span></span></span><span class="line"><span class="cl"><span class="s">    resource_group_name  = &#34;${RESOURCE_GROUP_NAME}&#34;
</span></span></span><span class="line"><span class="cl"><span class="s">    storage_account_name = &#34;${STORAGE_ACCOUNT_NAME}&#34;
</span></span></span><span class="line"><span class="cl"><span class="s">    container_name       = &#34;${CONTAINER_NAME}&#34;
</span></span></span><span class="line"><span class="cl"><span class="s">    key                  = &#34;terraform.tfstate&#34;
</span></span></span><span class="line"><span class="cl"><span class="s">  }
</span></span></span><span class="line"><span class="cl"><span class="s">}
</span></span></span><span class="line"><span class="cl"><span class="s">EOF</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">gum format <span class="s1">&#39;`## versions.tf`&#39;</span>
</span></span><span class="line"><span class="cl">gum format <span class="s1">&#39;`# include the provider in versions.tf`&#39;</span>
</span></span><span class="line"><span class="cl">gum format --type code --language<span class="o">=</span><span class="s2">&#34;HCL2&#34;</span> <span class="s">&lt;&lt;EOF
</span></span></span><span class="line"><span class="cl"><span class="s">terraform {
</span></span></span><span class="line"><span class="cl"><span class="s">  required_providers {
</span></span></span><span class="line"><span class="cl"><span class="s">    azurerm = {
</span></span></span><span class="line"><span class="cl"><span class="s">      source  = &#34;hashicorp/azurerm&#34;
</span></span></span><span class="line"><span class="cl"><span class="s">      version = &#34;3.88.0&#34;
</span></span></span><span class="line"><span class="cl"><span class="s">    }
</span></span></span><span class="line"><span class="cl"><span class="s">  }
</span></span></span><span class="line"><span class="cl"><span class="s">}
</span></span></span><span class="line"><span class="cl"><span class="s">EOF</span>
</span></span></code></pre></td></tr></table>
</div>
</div>
        ]]>
    </description>
</item>
</channel>
</rss>
